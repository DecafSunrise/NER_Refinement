{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Flair's NER\n",
    "\n",
    "As usual, let's just borrow best practices from someone who has done it before:  \n",
    "https://medium.com/analytics-vidhya/practical-approach-of-state-of-the-art-flair-in-named-entity-recognition-46a837e25e6b\n",
    "\n",
    "I came across Flair by accident, and was surprised to hear about a \"simple\" NLP package I hadn't heard of yet. The benchmarks against current SOTA are impressive, so let's give it a shot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "\n",
    "#import commands for flair NER\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate NER on a single string\n",
    "(Copied from the link above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load NER Model\n",
    "tagger = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample text to run NER\n",
    "text = 'Jackson is placed in Microsoft located in Redmond'\n",
    "#passing text to sentence\n",
    "sentence = Sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span [1]: \"Jackson\"   [− Labels: PER (0.9951)]\n",
      "Span [5]: \"Microsoft\"   [− Labels: ORG (0.9908)]\n",
      "Span [8]: \"Redmond\"   [− Labels: LOC (0.9586)]\n"
     ]
    }
   ],
   "source": [
    "# Run NER on sentence to identify Entities\n",
    "tagger.predict(sentence)\n",
    "# print the entities with below command\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooh, I like the percent confidence.\n",
    "\n",
    "### Great, let's try it on a full article\n",
    "\n",
    "- Go load my normal boilerpy article grabber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boilerpy3\n",
    "from boilerpy3 import extractors\n",
    "extractor = extractors.ArticleExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = extractor.get_doc_from_url(r\"https://www.washingtonpost.com/nation/2021/04/06/derek-chauvin-trial/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-07 00:27:15,310 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    }
   ],
   "source": [
    "#Import segtok library to split the paragraph into sentences\n",
    "from segtok.segmenter import split_single\n",
    "sentences = [Sentence(sent, use_tokenizer=True) for sent in split_single(doc.content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-07 00:27:42,581 Ignore 1 sentence(s) with no tokens.\n",
      "Span [1]: \"UTC\"   [− Labels: ORG (0.625)]\n",
      "Span [1]: \"MINNEAPOLIS\"   [− Labels: ORG (0.5678)]\n",
      "Span [7,8]: \"Derek Chauvin\"   [− Labels: PER (0.9999)]\n",
      "Span [26,27]: \"George Floyd\"   [− Labels: PER (0.9983)]\n",
      "Span [32]: \"Floyd\"   [− Labels: PER (1.0)]\n",
      "Span [1,2]: \"Johnny Mercil\"   [− Labels: PER (0.9996)]\n",
      "Span [7]: \"Minneapolis\"   [− Labels: LOC (0.9944)]\n",
      "Span [26]: \"Floyd\"   [− Labels: PER (0.9995)]\n",
      "Span [2,3]: \"Steve Schleicher\"   [− Labels: PER (0.9998)]\n",
      "Span [5]: \"Mercil\"   [− Labels: PER (0.9987)]\n",
      "Span [13]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [16]: \"Floyd\"   [− Labels: PER (0.9988)]\n",
      "Span [22]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [6]: \"Mercil\"   [− Labels: PER (0.9987)]\n",
      "Span [13]: \"MPD\"   [− Labels: ORG (0.9162)]\n",
      "Span [14]: \"Mercil\"   [− Labels: PER (0.9975)]\n",
      "Span [2,3]: \"Eric Nelson\"   [− Labels: PER (0.9999)]\n",
      "Span [5]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [23]: \"Floyd\"   [− Labels: PER (0.999)]\n",
      "Span [3]: \"Mercil\"   [− Labels: PER (0.9943)]\n",
      "Span [23]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [27]: \"Floyd\"   [− Labels: PER (0.7249)]\n",
      "Span [5]: \"Nelson\"   [− Labels: PER (1.0)]\n",
      "Span [28]: \"Floyd\"   [− Labels: PER (0.9994)]\n",
      "Span [1]: \"Nelson\"   [− Labels: PER (0.9998)]\n",
      "Span [12]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [16]: \"Floyd\"   [− Labels: PER (0.992)]\n",
      "Span [6]: \"Mercil\"   [− Labels: PER (0.9987)]\n",
      "Span [1]: \"Mercil\"   [− Labels: PER (0.9997)]\n",
      "Span [6]: \"Minneapolis\"   [− Labels: LOC (0.9998)]\n",
      "Span [22]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [32]: \"Floyd\"   [− Labels: PER (0.9998)]\n",
      "Span [15]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [26]: \"Floyd\"   [− Labels: PER (0.9999)]\n",
      "Span [35,36]: \"South Minneapolis\"   [− Labels: LOC (0.9618)]\n",
      "Span [39]: \"Floyd\"   [− Labels: PER (1.0)]\n",
      "Span [1]: \"Chauvin\"   [− Labels: PER (0.9596)]\n",
      "Span [8]: \"Floyd\"   [− Labels: PER (0.9986)]\n",
      "Span [17]: \"Chauvin\"   [− Labels: PER (0.9999)]\n",
      "Span [44]: \"Floyd\"   [− Labels: PER (0.9997)]\n",
      "Span [7]: \"Chauvin\"   [− Labels: PER (0.9999)]\n",
      "Span [2,3]: \"Ker Yang\"   [− Labels: PER (0.9987)]\n",
      "Span [20]: \"Yang\"   [− Labels: PER (1.0)]\n",
      "Span [6]: \"Nelson\"   [− Labels: PER (1.0)]\n",
      "Span [1]: \"Nelson\"   [− Labels: PER (1.0)]\n",
      "Span [5]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [13]: \"Chicago\"   [− Labels: LOC (0.9996)]\n",
      "Span [21]: \"Floyd\"   [− Labels: PER (0.9994)]\n",
      "Span [1]: \"Nelson\"   [− Labels: PER (0.9998)]\n",
      "Span [3]: \"Yang\"   [− Labels: PER (1.0)]\n",
      "Span [1]: \"Nelson\"   [− Labels: PER (0.9998)]\n",
      "Span [6]: \"Yang\"   [− Labels: PER (0.9641)]\n",
      "Span [1]: \"Nelson\"   [− Labels: PER (1.0)]\n",
      "Span [8,9]: \"Nicole Mackenzie\"   [− Labels: PER (0.9993)]\n",
      "Span [23]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [4]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [1,2]: \"Alexander Kueng\"   [− Labels: PER (0.9999)]\n",
      "Span [4,5,6]: \"Thomas K. Lane\"   [− Labels: PER (0.9988)]\n",
      "Span [8,9]: \"Tou Thao\"   [− Labels: PER (0.9993)]\n",
      "Span [14]: \"CPR\"   [− Labels: ORG (0.5509)]\n",
      "Span [20]: \"Floyd\"   [− Labels: PER (0.9997)]\n",
      "Span [2]: \"Mackenzie\"   [− Labels: PER (1.0)]\n",
      "Span [7]: \"Nelson\"   [− Labels: PER (0.9999)]\n",
      "Span [38]: \"Mackenzie\"   [− Labels: PER (1.0)]\n",
      "Span [3]: \"Mackenzie\"   [− Labels: PER (1.0)]\n",
      "Span [16]: \"MPD\"   [− Labels: ORG (0.9999)]\n",
      "Span [4]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [6]: \"Floyd\"   [− Labels: PER (1.0)]\n",
      "Span [21]: \"Mackenzie\"   [− Labels: PER (1.0)]\n",
      "Span [6,7]: \"Jody Stiger\"   [− Labels: PER (0.9999)]\n",
      "Span [14,15,16,17]: \"Los Angeles Police Department\"   [− Labels: ORG (0.812)]\n",
      "Span [26]: \"Chauvin\"   [− Labels: PER (0.9986)]\n",
      "Span [1]: \"Stiger\"   [− Labels: PER (0.9999)]\n",
      "Span [7]: \"LAPD\"   [− Labels: ORG (0.9997)]\n",
      "Span [6,7]: \"Cup Foods\"   [− Labels: ORG (0.6864)]\n",
      "Span [14]: \"Floyd\"   [− Labels: PER (0.9997)]\n",
      "Span [26]: \"Stiger\"   [− Labels: PER (1.0)]\n",
      "Span [48]: \"Floyd\"   [− Labels: PER (0.9971)]\n",
      "Span [1]: \"Stiger\"   [− Labels: PER (1.0)]\n",
      "Span [1]: \"Stiger\"   [− Labels: PER (0.9999)]\n",
      "Span [36]: \"Floyd\"   [− Labels: PER (0.9991)]\n",
      "Span [4]: \"Floyd\"   [− Labels: PER (1.0)]\n",
      "Span [28]: \"Stiger\"   [− Labels: PER (1.0)]\n",
      "Span [13,14]: \"Hennepin County\"   [− Labels: LOC (0.9218)]\n",
      "Span [17,18,19]: \"Peter A. Cahill\"   [− Labels: PER (0.9998)]\n",
      "Span [1]: \"Stiger\"   [− Labels: PER (0.9999)]\n",
      "Span [19]: \"Chauvin\"   [− Labels: PER (0.9968)]\n",
      "Span [1,2]: \"Derek Chauvin\"   [− Labels: PER (0.9998)]\n",
      "Span [6,7]: \"George Floyd\"   [− Labels: PER (0.9993)]\n",
      "Span [15,16,17]: \"Morries Lester Hall\"   [− Labels: PER (0.8553)]\n",
      "Span [27]: \"Floyd\"   [− Labels: PER (0.9999)]\n",
      "Span [1]: \"Hall\"   [− Labels: PER (0.9989)]\n",
      "Span [20,21]: \"Fifth Amendment\"   [− Labels: MISC (0.648)]\n",
      "Span [1]: \"Hall\"   [− Labels: PER (0.9993)]\n",
      "Span [16]: \"Floyd\"   [− Labels: PER (0.9998)]\n",
      "Span [36]: \"Chauvin\"   [− Labels: PER (1.0)]\n",
      "Span [55]: \"Floyd\"   [− Labels: PER (0.9999)]\n",
      "Span [4,5]: \"Courteney Ross\"   [− Labels: PER (0.9993)]\n",
      "Span [7]: \"Floyd\"   [− Labels: PER (0.998)]\n",
      "Span [26]: \"Hall\"   [− Labels: LOC (0.7318)]\n",
      "Span [7,8]: \"Cup Foods\"   [− Labels: ORG (0.7383)]\n",
      "Span [11]: \"Hall\"   [− Labels: PER (0.9998)]\n",
      "Span [28]: \"Floyd\"   [− Labels: PER (0.9997)]\n",
      "Span [1]: \"Nelson\"   [− Labels: PER (1.0)]\n",
      "Span [7]: \"Hall\"   [− Labels: PER (0.9969)]\n",
      "Span [9]: \"Floyd\"   [− Labels: PER (0.9999)]\n",
      "Span [30,31]: \"Cup Foods\"   [− Labels: MISC (0.8506)]\n",
      "Span [36]: \"Floyd\"   [− Labels: PER (0.9973)]\n",
      "Span [1]: \"Nelson\"   [− Labels: PER (1.0)]\n",
      "Span [8]: \"Hall\"   [− Labels: PER (0.9958)]\n",
      "Span [30]: \"Floyd\"   [− Labels: PER (0.998)]\n",
      "Span [1]: \"Hall\"   [− Labels: PER (0.9994)]\n",
      "Span [18]: \"Minneapolis\"   [− Labels: LOC (1.0)]\n",
      "Span [32,33]: \"Adrienne Cousins\"   [− Labels: PER (0.9999)]\n",
      "Span [9]: \"Floyd\"   [− Labels: PER (0.9996)]\n",
      "Span [23]: \"Cousins\"   [− Labels: PER (1.0)]\n",
      "Span [5]: \"Hall\"   [− Labels: PER (0.9326)]\n",
      "Span [1]: \"Cahill\"   [− Labels: PER (1.0)]\n",
      "Span [6]: \"Hall\"   [− Labels: PER (0.9966)]\n",
      "Span [29]: \"Floyd\"   [− Labels: PER (0.9999)]\n",
      "Span [8]: \"Hall\"   [− Labels: PER (0.9999)]\n",
      "Span [12,13]: \"Matthew Frank\"   [− Labels: PER (0.9999)]\n",
      "Span [11]: \"Hall\"   [− Labels: PER (0.98)]\n",
      "Span [1]: \"Cahill\"   [− Labels: PER (1.0)]\n",
      "Span [1,2]: \"Meryl Kornfield\"   [− Labels: PER (0.988)]\n"
     ]
    }
   ],
   "source": [
    "#predicting entities\n",
    "tagger.predict(sentences)\n",
    "# print the entities with below command\n",
    "for sent in sentences:\n",
    "    for entity in sent.get_spans('ner'):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try another one  \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = extractor.get_doc_from_url(r\"https://www.cnn.com/2021/04/06/health/covid-neurological-psychological-lancet-wellness/index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-07 00:42:29,886 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    }
   ],
   "source": [
    "#Import segtok library to split the paragraph into sentences\n",
    "from segtok.segmenter import split_single\n",
    "sentences = [Sentence(sent, use_tokenizer=True) for sent in split_single(doc.content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-07 00:42:37,826 Ignore 1 sentence(s) with no tokens.\n",
      "Span [2]: \"Birx\"   [− Labels: PER (0.6829)]\n",
      "Span [10]: \"Covid-19\"   [− Labels: MISC (0.9864)]\n",
      "Span [6]: \"Covid-19\"   [− Labels: MISC (0.8169)]\n",
      "Span [33,34]: \"Lancet Psychiatry\"   [− Labels: ORG (0.8155)]\n",
      "Span [16]: \"Covid-19\"   [− Labels: MISC (0.9149)]\n",
      "Span [11]: \"Covid-19\"   [− Labels: MISC (0.7916)]\n",
      "Span [16,17]: \"Maxime Taquet\"   [− Labels: PER (0.9999)]\n",
      "Span [27,28,29]: \"University of Oxford\"   [− Labels: ORG (0.996)]\n",
      "Span [16]: \"Covid-19\"   [− Labels: MISC (0.776)]\n",
      "Span [15]: \"Covid-19\"   [− Labels: MISC (0.6785)]\n",
      "Span [12]: \"Taquet\"   [− Labels: PER (0.9999)]\n",
      "Span [20]: \"Covid-19\"   [− Labels: MISC (0.9739)]\n",
      "Span [26]: \"US\"   [− Labels: LOC (0.9974)]\n",
      "Span [6]: \"Covid-19\"   [− Labels: MISC (0.9867)]\n",
      "Span [5]: \"Covid-19\"   [− Labels: MISC (0.9618)]\n",
      "Span [3]: \"Covid-19\"   [− Labels: ORG (0.5987)]\n",
      "Span [14]: \"Taquet\"   [− Labels: PER (1.0)]\n",
      "Span [12]: \"Covid-19\"   [− Labels: MISC (0.8482)]\n",
      "Span [27,28]: \"Musa Sami\"   [− Labels: PER (0.9997)]\n",
      "Span [38,39,40]: \"University of Nottingham\"   [− Labels: ORG (0.9888)]\n",
      "Span [17]: \"Covid-19\"   [− Labels: MISC (0.9348)]\n",
      "Span [15]: \"Covid-19\"   [− Labels: MISC (0.7806)]\n",
      "Span [1]: \"Sami\"   [− Labels: PER (0.9999)]\n",
      "Span [16,17]: \"Masud Husain\"   [− Labels: PER (0.9994)]\n",
      "Span [28,29,30]: \"University of Oxford\"   [− Labels: ORG (0.9954)]\n",
      "Span [10]: \"Covid-19\"   [− Labels: MISC (0.6954)]\n",
      "Span [15]: \"Rome\"   [− Labels: LOC (0.9994)]\n",
      "Span [17]: \"Italy\"   [− Labels: LOC (0.9999)]\n",
      "Span [13]: \"Covid-19\"   [− Labels: MISC (0.677)]\n",
      "Span [1]: \"Covid-19\"   [− Labels: ORG (0.6959)]\n",
      "Span [5]: \"Lancet\"   [− Labels: ORG (0.3466)]\n",
      "Span [24,25]: \"Paul Harrison\"   [− Labels: PER (0.9999)]\n",
      "Span [33,34,35]: \"University of Oxford\"   [− Labels: ORG (0.9958)]\n",
      "Span [5]: \"Covid-1919\"   [− Labels: MISC (0.9684)]\n",
      "Span [17]: \"Taquet\"   [− Labels: PER (0.9999)]\n",
      "Span [2,3]: \"CNN Health\"   [− Labels: ORG (0.9211)]\n",
      "Span [12,13]: \"Sanjay Gupta\"   [− Labels: PER (0.9923)]\n",
      "Span [18,19]: \"CNN Health\"   [− Labels: ORG (0.9089)]\n",
      "Span [43]: \"Harrison\"   [− Labels: PER (0.9999)]\n",
      "Span [1]: \"CNN\"   [− Labels: ORG (0.9983)]\n",
      "Span [3,4]: \"Chloe Adams\"   [− Labels: PER (0.9998)]\n"
     ]
    }
   ],
   "source": [
    "#predicting entities\n",
    "tagger.predict(sentences)\n",
    "# print the entities with below command\n",
    "for sent in sentences:\n",
    "    for entity in sent.get_spans('ner'):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts\n",
    "\n",
    "- Flair's NER seems to work pretty well. \n",
    "- That article is less robust/difficult than some docs I'd want to throw through NER, but it's a decent test. \n",
    "- You can see **it thought \"UTC\" was an org** (It's a timezone).\n",
    "- There are fewer tag types than you'd find with SpaCy\n",
    "- **It's weird that some labels come back at 1.0**; seems a little cocky!\n",
    "\n",
    "I found this article, which you might get some use out of if you're trying to benchmark NER and Semantic Annotation Platforms.\n",
    "https://towardsdatascience.com/benchmark-ner-algorithm-d4ab01b2d4c3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coding",
   "language": "python",
   "name": "coding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
